\chapter{Fundamentos de teoría de códigos}

En la introducción ya hemos visto cuáles son los objetivos de la teoría de códigos, así como el medio principal del que se sirve: el álgebra.
Esta sección vamos a comentar algunos de los conceptos y resultados fundamentales de la teoría de códigos.
Daremos la definición más sencilla de código para posteriormente estudiar otras estructuras más complejas, los códigos lineales y los códigos cíclicos, así como resultados básicos asociados a ellos.
Finalmente, estudiaremos la versión original del algoritmo de Peterson-Gorenstein-Zierler, diseñado para un tipo de códigos, los \textacr{BCH}.

Las definiciones y los resultados comentados en esta sección seguirán lo descrito en \parencite[cap. 1, 3-5]{huffman_fundamentals_2003} y \parencite{podesta_introduccion_2006}.

\section{Códigos lineales}

Vamos a comenzar nuestro estudio con los códigos lineales, pues son los más sencillos de comprender. 
Consideremos el espacio vectorial de todas las \(n\)-tuplas sobre el cuerpo finito \(\mathbb F_q\), al que denotaremos en lo que sigue como \(\mathbb F_q^n\). 
A los elementos \((a_1, \dots, a_n)\) de \(\mathbb F_q^n\) los notaremos usualmente como \(a_1\!\cdots a_n\).

\begin{definition}
  Un \((n, M)\) \textit{código} \(\mathcal C\) sobre el cuerpo \(\mathbb F_q\) es un subconjunto de \(\mathbb F_q^n\) de tamaño \(M\). 
  Si no hay riesgo de confusión lo denotaremos simplemente por \(\mathcal C\). 
  A los elementos de \(\mathcal C\) los llamaremos \textit{palabras codificadas}, \textit{palabras código} o \textit{codewords} en inglés.
  A \(n\) se le llama \(longitud\) del código.
\end{definition}

Por ejemplo, un \((5,4)\) código sobre \(\mathbb F_2\) puede ser el formado por los siguientes elementos: \[
  10101,\qquad
  10010,\qquad
  01110,\qquad
  11111.
\]
Como se puede ver realmente un código es un objeto muy sencillo.
Concluimos que es necesario añadir más estructura a los códigos para que puedan ser de utilidad.
Esto motiva la siguiente definición.

\begin{definition}
  Decimos que un código \(\mathcal C\) es un código \textit{lineal de longitud \(n\) y dimensión \(k\)} —abreviado como \([n, k]\)-\textit{lineal}, o como \([n, k]_q\)~-\textit{lineal} en caso de querer informar del cuerpo base— si dicho código es un subespacio vectorial de \(\mathbb F_q^n\) de dimensión \(k\).
\end{definition}

\begin{remark}
  Un código lineal \(\mathcal C\) tiene \(q^k\) palabras código.
\end{remark}

Así, hemos pasado de trabajar con un objeto que no tiene estructura alguna a trabajar con espacios vectoriales, cuyas propiedades son ampliamente conocidas y disponemos de numerosas herramientas para tratarlos.
Por ejemplo, en ocasiones hablaremos de \emph{subcódigos} de un código \(\mathcal C\).
Si \(\mathcal C\) es un código lineal entonces el subcódigo será un subespacio vectorial del mismo.
En caso de que sea no lineal un subcódigo será simplemente un subconjunto de \(\mathcal C\).

Veamos en la siguiente definición otro ejemplo de las herramientas que nos proporciona trabajar con espacios vectoriales.

\begin{definition}
  Una \textit{matriz generadora} para un \([n, k]\) código \(\mathcal C\) es una matriz \(k \times n\) cuyas filas conforman una base de \(\mathcal C\)\footnote{Efectivamente la matriz generadora no es única: basta tomar la correspondiente a cualquier otra base del código —que no deja de ser un espacio vectorial— para obtener una distinta. Pero es más, podemos simplemente reordenar las filas de una matriz generadora y en esencia estaremos obteniendo otra distinta.}.
\end{definition}



\begin{definition}
  Para cada conjunto \(k\) de columnas independientes de una matriz generadora \(G\) el conjunto de coordenadas correspondiente se denomina \textit{conjunto de información} para un código \(\mathcal C\). 
  Las \(r = n - k\) coordenadas restantes se llaman \textit{conjunto redundante}, y el número \(r\), la \textit{redundancia} de \(\mathcal C\).
\end{definition}

Si las primeras \(k\) coordenadas de una matriz generadora \(G\) forman un conjunto de información entonces el código tiene una única matriz generadora de la forma \([I_k \mid A]\), donde \(I_k\) es la matriz identidad \(k \times k\) y \(A\) es una matriz \(k \times r\). 
Esta matriz generadora se dice que está en \textit{forma estándar}.
A partir de cualquier matriz generadora siempre es posible obtener una matriz en forma estándar realizando una permutación adecuada de las coordenadas.
%Esta matriz resultante no será una matriz generadora del código inicial, pero sí de un código equivalente.

%Como un código lineal es el subespacio de un espacio vectorial, es el núcleo de una transformación lineal. En particular, existe una matriz \(H\) de dimensiones \(r \times n\), llamada \textit{matriz de comprobación de paridad} para un \([n, k]\) código \(\mathcal C\) definida por \begin{equation}
%  \mathcal C = \left\{x \in \mathbb F_q^n : H \mathbf x^T = 0 %\right\}.
%\end{equation}

Como un código lineal \(\mathcal C\) es un subespacio de un espacio vectorial, podemos calcular el ortogonal a dicho subespacio, obteniendo lo que llamaremos el \textit{código dual} (\textit{euclídeo}, si usamos el producto escalar usual) y que denotaremos por \(\mathcal C^{\perp}\).

\begin{definition}
  El \textit{código dual} \(\mathcal C^{\perp}\) de un código \(\mathcal C\) viene dado por \[\mathcal C^{\perp} = \left\{x \in \mathbb F_q^n : x \cdot c = 0 \quad \forall c \in \mathcal C\right\},\]
  donde \((\cdot)\) representa el producto escalar usual.
\end{definition}

\begin{definition}
  Sea \(\mathcal C\) un \([n, k]\) código lineal. Una matriz \(H\) se dice que es \textit{matriz de paridad} si es una matriz generadora de \(\mathcal C^{\perp}\).
\end{definition}

\begin{proposition}
  \label{prop:cod-por-matriz-paridad}
  Sea \(H\) la matriz de paridad de un \([n, k]\) código lineal \(\mathcal C\). 
  Entonces, \[\mathcal C = \left\{x \in \mathbb F_q^n : xH^T = 0\right\} = \left\{x \in F_q^n : Hx^T = 0\right\}.\]
\end{proposition}

\begin{proof}
  Sea \(c \in \mathcal C\) una palabra código. 
  Sabemos que la podemos expresar como \(c = uG\), donde \(u \in \mathbb F_q^k\) y \(G\) es una matriz generadora de \(\mathcal C\). 
  Tenemos entonces que \(c\cramped{H^T} = uG\cramped{H^T}\) y como \(G\cramped{H^T} = 0\) —por ser H matriz generadora del subespacio ortogonal \(\mathcal C\)— se tiene que \[\mathcal C \subset S_H = \left\{x \in \mathbb F_q^n : Hx^T = 0\right\},\] que es el espacio solución de un sistema de \(n - k\) ecuaciones con \(n\) incógnitas y de rango \(n - k\). Como \(\dim(S_H) = n - (n - k) = k = \dim L\), concluimos que \[L = S_H = \left\{x \in \mathbb F_q^n : Hx^T = 0\right\}.\qedhere\]
\end{proof}

Este último resultado, junto a la definición previa, nos conducen al siguiente teorema. 

\begin{theorem}
  Si \(G = [I_k \mid A]\) es una matriz generadora para un \([n, k]\) código \(\mathcal C\) en forma estándar entonces \(H = [-A \mid I_{n-k}]\) es una matriz de paridad para \(\mathcal C\).
\end{theorem}

Como nota final sobre nomenclatura de códigos duales, apuntamos que un código se dice \textit{autoortogonal} cuando \(\mathcal C \subseteq \mathcal C^{\perp}\), y \textit{autodual} cuando \(\mathcal C = \mathcal C^{\perp}\).

\subsection{Codificación y decodificación}
\label{subsec:codificacion-descodificacion}

Codificar un mensaje consiste en escribirlo como palabra código de un código.
La forma estándar de codificar mensajes con códigos lineales es utilizando una matriz generadora.
Dado un mensaje \(\mathbf{m} \in \mathbb F_q^k\) podemos obtener la palabra código \(\mathbf{c}\) en \(\mathcal C\) realizando la operación \(\mathbf{c}= \mathbf{m}G\).
Vamos a verlo mejor con un ejemplo.

\begin{example}
  Sea \(\mathcal C\) \([3, 2]\) un código binario lineal y \(G\) la matriz generadora dada por 
  \[
    G = \begin{pmatrix}
      1 & 1 & 0 \\ 0 & 1 & 1
    \end{pmatrix} \in \mathcal M_{2 \times 3}(\mathbb F_2).
  \]
  Dado un mensaje \(\mathbf{m} = (x_1, x_2)\), se tiene que \[(x_1, x_2) \begin{pmatrix}
    1 & 1 & 0 \\ 0 & 1 & 1
  \end{pmatrix} = (x_1, x_1 + x_2, x_2),\] y por tanto esta matriz codifica de la forma \[00 \to 000, \quad 01 \to 011,\quad 10 \to 110,\quad 11 \to 101.\]
\end{example}

Observamos que una matriz generador \(G\) define una aplicación lineal de \(\mathbb F_q^k\) en \(\mathbb F_q^n\), de forma que el código obtenido es la imagen de dicha aplicación.
Podemos comprobar también que es posible codificar en los mismos códigos lineales utilizando distintas matrices generadores, lo que resultará en distintas palabras código para el mismo mensaje.
Veamos un ejemplo con el mismo código binario lineal que en el ejemplo anterior pero con distinta matriz generadora.

\begin{example}
  Sea \(\mathcal C\) un \([3, 2]\) código binario lineal y \(G\) la matriz generadora dada por 
  \[
    G = \begin{pmatrix}
      1 & 0 & 1 \\ 0 & 1 & 1
    \end{pmatrix} \in \mathcal M_{2 \times 3}(\mathbb F_2).
  \]
  Dado un mensaje \(\mathbf{m} = (x_1, x_2)\), se tiene que \[(x_1, x_2) \begin{pmatrix}
    1 & 0 & 1 \\ 0 & 1 & 1
  \end{pmatrix} = (x_1, x_2, x_1 + x_2),\] y por tanto esta matriz codifica de la forma \[00 \to 000, \quad 01 \to 011,\quad 10 \to 101,\quad 11 \to 110.\]
\end{example}

Observamos en este ejemplo que las primeras \(2\) coordenadas de cada palabra código son iguales a las del mensaje que las genera.
Pero en el código anterior también podemos encontrar el mensaje, lo que hay que fijarse en la primera y última coordenada.
Cuando un mensaje se encuentra incrustado íntegramente en la palabra código —aunque puede que desordenado— se dice que la codificación seguida es \textit{sistemática}.
En caso contrario, se dice que es \textit{no-sistemática}.
Veamos un ejemplo de codificación no-sistemática con el mismo código binario lineal de antes.

\begin{example}
  \label{ej:codificacion-no-sistematica}
  Sea \(\mathcal C\) un \([3, 2]\) código binario lineal y \(G\) la matriz generadora dada por 
  \[
    G = \begin{pmatrix}
      1 & 0 & 1 \\ 1 & 1 & 1
    \end{pmatrix} \in \mathcal M_{2 \times 3}(\mathbb F_2).
  \]
  Dado un mensaje \(\mathbf{m} = (x_1, x_2)\), se tiene que \[(x_1, x_2) \begin{pmatrix}
    1 & 0 & 1 \\ 1 & 1 & 1
  \end{pmatrix} = (x_1 + x_2, x_2, x_1 + x_2),\] y por tanto esta matriz codifica de la forma \[00 \to 000, \quad 01 \to 111,\quad 10 \to 101,\quad 11 \to 010.\]
  Comprobamos que los mensajes \(01\) y \(11\) no están contenidos en las palabras código correspondientes, \(111\) y \(010\), respectivamente, luego la codificación es no-sistemática.
\end{example}

Dada una palabra código \(\mathbf{c}\) si se desea obtener el mensaje \(\mathbf{m}\) a partir del que se obtuvo podemos realizar el procedimiento inverso a la codificación.
Para ello tenemos en cuenta que al codificar mediante una matriz generadora \(G\) de tamaño \(n \times k\) establecemos una correspondencia biyectiva entre mensajes y palabras código.
Existe por tanto una matriz \(K\) de tamaño \(k \times n\) llamada \textit{inversa por la derecha} tal que \(GK = I_k\).
Así, puesto que \(\mathbf{c} = \mathbf{m}G\) podemos obtener el mensaje original calculando \(\mathbf{c}K = \mathbf{m}GK = \mathbf{m}\).
Veamos un ejemplo de este proceso.

\begin{example}
  Sea \(\mathcal C\) un \([7, 3]\) código binario lineal y \(G\) la matriz generadora dada por 
  \[
    G = \left(\begin{array}{rrrrrrr}
      1 & 1 & 1 & 0 & 1 & 0 & 0 \\
      0 & 1 & 1 & 1 & 0 & 1 & 0 \\
      0 & 0 & 1 & 1 & 1 & 0 & 1
      \end{array}\right) \in \mathcal M_{3 \times 7}(\mathbb F_2).
  \]
  Esta matriz codifica el mensaje \(\mathbf{m} = (1, 0, 1)\) como:
  \[
    \mathbf{c} = (1, 0, 1)\left(\begin{array}{rrrrrrr}
      1 & 1 & 1 & 0 & 1 & 0 & 0 \\
      0 & 1 & 1 & 1 & 0 & 1 & 0 \\
      0 & 0 & 1 & 1 & 1 & 0 & 1
      \end{array}\right) = \left(1,\,1,\,0,\,1,\,0,\,0,\,1\right).
  \]
  Para realizar el procedimiento inverso buscamos una matriz \(K\) tal que \(GK = I_7\).
  Esta matriz viene dada por
  \[
    K = \left(\begin{array}{rrr}
      1 & 1 & 0 \\
      0 & 1 & 1 \\
      0 & 0 & 1 \\
      0 & 0 & 0 \\
      0 & 0 & 0 \\
      0 & 0 & 0 \\
      0 & 0 & 0
      \end{array}\right)
  \] y por tanto el mensaje original era
  \[
    \mathbf{m} = \left(1,\,1,\,0,\,1,\,0,\,0,\,1\right)\left(\begin{array}{rrr}
      1 & 1 & 0 \\
      0 & 1 & 1 \\
      0 & 0 & 1 \\
      0 & 0 & 0 \\
      0 & 0 & 0 \\
      0 & 0 & 0 \\
      0 & 0 & 0
      \end{array}\right) = (1, 0, 1).
  \]
  
\end{example}

El proceso de decodificación de los mensajes consiste en obtener una palabra código válida a partir de un mensaje recibido\footnote{Es importante llamar la atención sobre el hecho de que \textit{decodificar} no es el proceso inverso a \textit{codificar}. Codificar consiste en escribir un mensaje como palabra código y decodificar, en corregir los errores que se hayan podido producir en la transmisión de dicha palabra.}. 
Es una tarea mucho más complicada que los procesos comentados antes, pues como ya se ha mencionado hay que tener en cuenta las posibles interferencias que se hayan podido producir en la comunicación.
Existen numerosos métodos de decodificación, y en general, cada familia de códigos tendrá un sistema que se aproveche de sus propiedades para ofrecer mejores prestaciones.
Destacamos de entre todos ellos un sistema aplicable a los códigos lineales, el conocido como \emph{decodificación por síndromes}, pues en él se basará el algoritmo cuya descripción es el objetivo de este trabajo.
Este método se basa en la propiedad de la matriz de paridad de que para toda palabra código \(\mathbf{c} \in \mathcal C\) se tiene que \(H \mathbf{c} = 0\).
Someramente el método consiste en computar y almacenar previamente los resultados del producto de todos los posibles vectores error y cuando se recibe un mensaje \(\mathbf{y} = \mathbf{c} + \mathbf{e}\), donde \(\mathbf{e}\) representa el error que se ha producido en la transmisión, se calcula lo que se conoce como \emph{síndrome}, que es el producto
\[
  H \mathbf{y} = H(\mathbf{c} + \mathbf{e}) = H \mathbf{c} + H \mathbf{e} = H \mathbf{e}.
\]
Este síndrome obtenido se compara con los productos previamente calculados para determinar qué error \(\mathbf{e}\) se ha producido y el mensaje codificado se obtiene como \(\mathbf{c} = \mathbf{y} - \mathbf{e}\).
%Los métodos de decodificación de códigos lineales en general se escapan del alcance de este trabajo, pues su objetivo principal es la descripción de un algoritmo de decodificación para un tipo concreto de códigos que veremos más adelante.

\subsection{Distancias y pesos}

Códigos distintos poseen distintas propiedades, lo que implica que sus capacidades de corrección difieran.
En este apartado vamos a estudiar dos propiedades de los códigos muy relacionadas con esta idea.

\begin{definition}
  La \textit{distancia de Hamming} \(\operatorname{d}(\symbf{x}, \symbf{y})\) entre dos vectores \(\symbf{x}, \symbf{y} \in \mathbb F_q^n\) se define como el número de coordenadas en las que difieren \(\symbf{x}\) e \(\symbf{y}\).
\end{definition}

\begin{theorem}
  La función de distancia \(\operatorname{d}(\symbf{x}, \symbf{y})\) verifica las siguientes propiedades.
  \begin{enumerate}
    \item No negatividad: \(\operatorname{d}(\symbf{x}, \symbf{y}) \geq 0\) para todo \(\symbf{x}, \symbf{y}\in \mathbb F_q^n\).
    \item La distancia \(\operatorname{d}(\symbf{x}, \symbf{y}) = 0\) si y solo si \(\symbf{x} = \symbf{y}\).
    \item Simetría: \(\operatorname{d}(\symbf{x}, \symbf{y}) = \operatorname{d}(\symbf{y}, \symbf{x})\) para todo \(\symbf{x}, \symbf{y}\in \mathbb F_q^n\).
    \item Desigualdad triangular: \(\operatorname{d}(\symbf{x}, \symbf{z}) \leq \operatorname{d}(\symbf{x}, \symbf{y}) + \operatorname{d}(\symbf{y}, \symbf{z})\) para todo elemento \(\symbf{x}, \symbf{y}, \symbf{z}\in \mathbb F_q^n\).
  \end{enumerate}
\end{theorem}

\begin{proof}
  
\end{proof}

La \textit{distancia} (\textit{mínima}) de un código \(\mathcal C\) es la menor distancia posible entre dos palabras código distintas. 
Si la distancia mínima \(d\) de un \([n,k]\) código es conocida, nos referiremos a él como un \([n,k,d]\) código.
Este valor es importante pues nos ayuda a determinar la capacidad de corrección de errores del código \(\mathcal C\), como ilustra el siguiente teorema.

\begin{theorem}
  Sea \(\mathcal C\) un \([n, k, d]\) código. Entonces \(\mathcal C\) tiene capacidad de corrección de errores \[
    t = \left\lfloor \frac{d - 1}{2} \right\rfloor.
  \]
\end{theorem}

% MAYBE: hablar también de la capacidad de detección de errores? l = d - 1

Efectivamente, a mayor distancia mínima, mayor número de errores en el código se pueden corregir.
Otra medida interesante es el \textit{peso de Hamming}.

\begin{definition}
  El \textit{peso de Hamming} \(\operatorname{wt}(\symbf{x})\) de un vector \(\symbf{x}\) es el número de coordenadas distintas de cero de \(\symbf{x}\).
\end{definition}

El siguiente teorema nos ilustra la relación existente entre los conceptos de peso y distancia.

\begin{theorem}
  Si \(\symbf{x}, \symbf{y} \in \mathbb F_q^n\), entonces \(\operatorname{d}(\symbf{x}, \symbf{y}) = \operatorname{wt}(\symbf{x} - \symbf{y})\).
  Si \(\mathcal C\) es un código lineal, la distancia mínima es igual al peso mínimo de las palabras código de \(\mathcal C\) distintas de cero.
\end{theorem}

\begin{proof}
  
\end{proof}

Como consecuencia de este teorema —para códigos lineales— la distancia mínima también se llama \textit{peso mínimo} del código.

\begin{definition}
  Sea \(A_i(\mathcal C)\) —que abreviaremos \(A_i\)— el número de palabras código de peso \(i\) en \(\mathcal C\).
  Para cada \(0 \leq i \leq n\), la lista \(A_i\) se denomina \textit{distribución de peso} o \textit{espectro de peso} de \(\mathcal C\).
\end{definition}

\begin{example}
  Sea \(\mathcal C\) el código binario con matriz generadora
  \[
    G = \begin{pmatrix}
      1 & 1 & 0 & 0 & 0 & 0\\
      0 & 0 & 1 & 1 & 0 & 0 \\
      0 & 0 & 0 & 0 & 1 & 1
    \end{pmatrix}.
  \]
  Dado \((x_1, x_2, x_3)\), se tiene que \[(x_1, x_2, x_3) \begin{pmatrix}
    1 & 1 & 0 & 0 & 0 & 0\\
      0 & 0 & 1 & 1 & 0 & 0 \\
      0 & 0 & 0 & 0 & 1 & 1
  \end{pmatrix} = (x_1, x_1, x_2, x_2, x_3, x_3),\] y por tanto podemos obtener las palabras código de la forma 
  \[
    000 \to 000000, \!\quad 
    001 \to 000011,\!\quad 
    010 \to 001100,\!\quad 
    011 \to 001111,
  \]
  \[
    100 \to 110000, \!\quad 
    101 \to 110011,\!\quad 
    110 \to 111100,\!\quad 
    111 \to 111111.
  \]
  Luego la distribución de peso de \(\mathcal C\) es \(A_0 = A_6 = 1\) y \(A_2 = A_4 = 3\).
  Usualmente solo se listan los \(A_i\) que son distintos de cero.
\end{example}

\begin{theorem}
  Sea \(\mathcal C\) un \([n,k,d]\) código sobre \(\mathbb F_q\).
  Entonces, \begin{enumerate}
    \item \(A_0(\mathcal C) + A_1(\mathcal C) + \cdots + A_n(\mathcal C) = q^k\).
    \item \(A_0(\mathcal C) = 1\) y \(A_1(\mathcal C) = A_2(\mathcal C) = \cdots = A_{d-1}(\mathcal C) = 0\).
  \end{enumerate}
\end{theorem}

\begin{proof}
  TODO
\end{proof}

% Theorem 1.4.13, Corollary 1.4.14 (Huffman-Pless), p.12-13

\begin{theorem}
  Sea \(\mathcal C\) un código lineal con matriz de paridad \(H\). Si \(\symbf{c} \in \mathcal C\), las columnas de \(H\) que se corresponden con coordenadas no nulas de \(\symbf{c}\) son linealmente independientes.
  Recíprocamente, si entre \(w\) columnas de \(H\) existe una relación de dependencia lineal con coeficientes no nulos, entonces hay una palabra código en \(\mathcal C\) de peso \(w\) cuyas coordenadas no nulas se corresponden con dichas columnas.
\end{theorem}

\begin{proof}
  TODO
\end{proof}

\begin{corollary}
  \label{cor:peso-minimo-columnas-dependientes}
  Un código lineal tiene peso mínimo \(d\) si y solo si su matriz de paridad tiene un conjunto de \(d\) columnas linealmente dependientes pero no tiene un conjunto de \(d-1\) columnas linealmente dependientes.
\end{corollary}

\begin{proof}
  TODO
\end{proof}

\section{Ejemplos de códigos}

En esta sección vamos a describir someramente algunas familias de códigos relevantes: los códigos de repetición, los códigos de control de paridad y los códigos de Hamming.

\subsection{Códigos de repetición}

Los códigos de repetición son una de las familias de códigos más sencillas.
Dado un mensaje \(\mathbf{m} = (m_1, m_2, \dots, m_n) \in \mathbb F_q^n\) lo que hacemos para codificarlo es repetir cada elemento \(m_i\) de la tupla \(k\) veces: 
\[
  \mathbf{c} = (m_{11}, m_{12}, \dots, m_{1k}, m_{21}, m_{22}, \dots, m_{2k}, \dots, m_{n1}, m_{n2}, \dots, m_{nk}).
\]
A la hora de decodificar un mensaje cada bloque de \(k\) elementos se fija al valor del elemento que más se repita. 
Los más utilizados son los códigos de repetición binarios, es decir, los que se definen sobre \(\mathbb F_2\).
No son códigos lineales.

\subsection{Códigos de control de paridad}

Los \([n, n -1]\)-códigos lineales que tienen matriz de paridad \[
  H = \begin{pmatrix}
    1 & 1 & \dots & 1
  \end{pmatrix}
\] se llaman \textit{códigos de control de paridad} o \textit{códigos de peso par}.
Por la proposición \ref{prop:cod-por-matriz-paridad} las palabras código \(\mathbf{c}\) de este tipo de códigos han de cumplir que
\[
  \mathbf{c}H^T = c_1 + c_2 + \dots + c_n = 0,
\]
es decir, el número de \(1\) en la palabra código ha de ser par —de ahí el nombre—.
La codificación de mensajes se realiza entonces añadiendo un \textit{bit} de paridad al final del mensaje cuyo valor se fija para que el número de \(1\) en el mismo sea par.
Estos códigos tienen distancia \(2\) y pueden corregir un solo error.

\subsection{Códigos de Hamming}

Consideremos una matriz \(r \times (2^r - 1)\) cuyas columnas son los números \(1, 2, 3, \dots, 2^{r-1}\) escritos en binario. 
Dicha matriz es la matriz de paridad de un \([n=2^{r-1}, k=n-r]\) código binario.
A los códigos de esta forma los llamaremos códigos de Hamming de longitud \(n = 2^{r-1}\) y los denotamos por \(\mathcal H_r\) o \(\mathcal H_{2,r}\).

Como las columnas son distintas y no nulas, la distancia es al menos \(3\) por el corolario \ref{cor:peso-minimo-columnas-dependientes}.
Además, como las columnas correspondientes a los números \(1, 2, 3\) son linealmente independientes, la distancia mínima es 3 por el mismo corolario.
Podemos decir por tanto que los códigos de Hamming \(\mathcal H_r\) son \([2^{r-1}, 2^{r-1-r}, 3]\) códigos binarios.

Podemos generalizar esta definición y definir los códigos de Hamming \(\mathcal H_{q,r}\) sobre un cuerpo finito arbitrario \(\mathbb F_q\). 
Para \(r \geq 2\) un código \(\mathcal H_{q,r}\) tiene matriz de paridad \(H_{q,r}\), cuyas columnas están compuestas por un vector no nulo por cada uno de los subespacios de dimensión \(1\) de \(\mathbb F_q^r\).
Hay \((q^r-1)/(q-1)\) subespacios de dimensión \(1\), por lo que \(\mathcal H_{q,r}\) tiene longitud \(n = (q^r-1)/(q-1)\), dimensión \(n-r\) y redundancia \(r\).
Como todas las columnas son independientes unas de otras, \(\mathcal H_{q,r}\) tiene peso mínimo al menos 3.
Si sumamos dos vectores no nulos de dos subespacios unidimensionales distintos obtenemos un vector no nulo de un tercer subespacio unidimensional, por lo que \(\mathcal H_{q,r}\) tiene peso mínimo 3. 
Cuando \(q = 2\), \(\mathcal H_{2,r}\) es el código \(\mathcal H_r\).

% TODO
% - por qué los códigos de Hamming son importantes
% - en qué se utilizan los códigos de Hamming