\chapter[Algoritmo PGZ para códigos cíclicos sesgados]{Algoritmo de Peterson-Gorenstein-Zierler para códigos cíclicos sesgados}

En este capítulo nos adentramos finalmente en el algoritmo que es el objeto de nuestro estudio, el algoritmo de Peterson-Gorenstein-Zierler para códigos cíclicos sesgados, y es una exposición de los resultados descritos en \parencite{gomez-torrecillas_petersongorensteinzierler_2018}.

Podemos asumir sin pérdida de generalidad que  \(\mathcal C\) es un código \textacr{RS} sesgado en sentido estricto, es decir, que bajo la definición que dimos en el capítulo anterior, el valor \(r = 0\).
De no ser así bastaría tomar \(\alpha' = \sigma^r(\alpha)\), que nos daría una base normal, y tendríamos \(\sigma^r(\beta) = \beta' = (\alpha')^{-1}\sigma(\alpha')\) por lo que el polinomio \([x - \beta', \dots, x - \sigma^{\delta - 2}(\beta')]_i\) sería un generador del código \(\mathcal C\).
Suponemos entonces que el ideal por la izquierda \(\mathfrak v^{-1}(\mathcal C)\) está generado por \([x - \beta, x - \sigma(\beta), \dots, x - \sigma^{\delta - 2}(\beta)]_i\) para algún \(2 \leq \delta \leq n\).
La distancia del código \(\mathcal C\) es \(\delta\) por el teorema \ref{th:distancia-skew-rs} y demostraremos más adelante que el algoritmo que vamos a describir permite corregir hasta \(t = \lfloor (\delta - 1)/2 \rfloor\) errores.

Nos encontramos en la misma situación que en casos anteriores.
Se quiere enviar un mensaje \(\mathbf{m} = (m_0, \dots, m_{n - \delta})\) a través de un canal.
Con la identificación de \(\mathcal C\) y \(\mathfrak v^{-1}(\mathcal C)\)podemos escribir \(\mathbf{m}\) como un polinomio, de forma que tenemos que \(m = \sum_{i=0}^{n-\delta}m_ix^{i}\).
Codificamos el mensaje realizando el producto por el generador, \(c = mg\).
Suponemos que recibimos el mensaje \(y = c + e\) donde \(e = e_1x^{k_1} + \dots + e_vx^{k_v}\) con \(v \leq t\) es el error que se ha producido durante la transmisión.
Para determinarlo es necesario por tanto conocer tanto las magnitudes de error \((e_{1}, \dots, e_{v})\) como las coordenadas de error \((k_1, \dots, k_v)\).

Vamos a describir un algoritmo para decodificar códigos cíclicos sesgados similar al ya descrito para códigos \textacr{BCH}.
Los pasos que dimos entonces fueron: \begin{enumerate}
  \item Determinar los síndromes del mensaje recibido.
  \item Encontrar el polinomio localizador.
  \item Obtener las coordenadas de error \(k_j\) y las magnitudes de error \(e_{j}\).
  \item Hallar el vector de error \(e(x)\) y restárselo al mensaje \(y(x)\).
\end{enumerate}
Esta versión del algoritmo sigue un esquema similar.
Así, el primer paso es el del cálculo de los síndromes, que será un procedimiento análogo al realizado entonces pero utilizando la definición de norma \(i\)-ésima de un elemento.
Por tanto para cada \(0 \leq i \leq 2t - 1\) el \emph{síndrome} \(i\)\emph{-ésimo} \(s_i\) del polinomio recibido \(y\) se define como el resto de dividir por la izquierda dicho polinomio \(y\) entre \(x - \sigma^{i}(\beta)\).
Como \(c\) es divisible por la derecha por cada \(x - \sigma^{i}(\beta)\) para \(i = 0, \dots, \delta - 2\) se tiene que 
\begin{align}
  s_i &= \sum_{j = 0}^{n-1}y_jN_j(\sigma^{i}(\beta)) = \sum_{j=1}^{v}e_jN_{k_j}(\sigma^{i}(\beta))\nonumber\\
   &= \sum_{j = 1}^{v}e_j\sigma^{i}(\alpha^{-1})\sigma^{i+k_j}(\alpha) = \sigma^{i}(\alpha^{-1})\sum_{j = 1}^{v}e_j\sigma^{i+k_j}(\alpha).
   \label{eq:sindromes-sesgados}
\end{align}

La siguiente proposición nos proporciona una forma de obtener las magnitudes de error a partir de las coordenadas de error y los síndromes, tal y como ocurría en el caso de códigos \textacr{BCH}.

\begin{proposition}
  \label{prop:pgz-sesgados-magnitudes-error}
  Las magnitudes de error \((e_{1}, \dots, e_{v})\) son las soluciones del sistema de ecuaciones lineales
  \[
    X \begin{pmatrix}
     \sigma^{k_1}(\alpha) & \sigma^{k_1 + 1}(\alpha) & \dots & \sigma^{k_1 + v - 1}(\alpha)\\ 
     \sigma^{k_2}(\alpha) & \sigma^{k_2 + 1}(\alpha) & \dots & \sigma^{k_2 + v - 1}(\alpha)\\ 
     \vdots & \vdots & \ddots & \vdots\\ 
     \sigma^{k_v}(\alpha) & \sigma^{k_v + 1}(\alpha) & \dots & \sigma^{k_v + v - 1}(\alpha)\\ 
    \end{pmatrix}
    = (\alpha s_0, \sigma(\alpha)s_1, \dots, \sigma^{v-1}(\alpha)s_{v-1}).
  \]
\end{proposition}

\begin{proof}
  Comenzamos viendo que
  \begin{align*}
    &\phantom{={}} \begin{pmatrix}
      \sigma^{k_1}(\alpha) & \sigma^{k_1 + 1}(\alpha) & \dots & \sigma^{k_1 + v - 1}(\alpha)\\ 
      \sigma^{k_2}(\alpha) & \sigma^{k_2 + 1}(\alpha) & \dots & \sigma^{k_2 + v - 1}(\alpha)\\ 
      \vdots & \vdots & \ddots & \vdots\\ 
      \sigma^{k_v}(\alpha) & \sigma^{k_v + 1}(\alpha) & \dots & \sigma^{k_v + v - 1}(\alpha)\\ 
     \end{pmatrix}\\
     &= \begin{pmatrix}
      \sigma^{k_1}(\alpha) & \sigma(\sigma^{k_1}(\alpha)) & \dots & \sigma^{v - 1}(\sigma^{k_1}(\alpha))\\ 
      \sigma^{k_2}(\alpha) & \sigma(\sigma^{k_2}(\alpha)) & \dots & \sigma^{v - 1}(\sigma^{k_2}(\alpha))\\ 
      \vdots & \vdots & \ddots & \vdots\\ 
      \sigma^{k_v}(\alpha) & \sigma(\sigma^{k_v}(\alpha)) & \dots & \sigma^{v - 1}(\sigma^{k_v}(\alpha))\\ 
     \end{pmatrix},
  \end{align*}
  que por \parencite[Lema 2.1]{gomez-torrecillas_petersongorensteinzierler_2018} es no singular.
  Por (\ref{eq:sindromes-sesgados}) tenemos que 
  \[
    \sigma^{i}(\alpha)s_i = \sum_{j = 1}^{v}e_j\sigma^{i + k_j}(\alpha),
  \]
  por lo que es evidente que dado \(X = (e_1, \dots, e_v)\) tenemos que
  \[
    (e_1, \dots, e_v) \begin{pmatrix}
      \sigma^{k_1}(\alpha) & \sigma^{k_1 + 1}(\alpha) & \dots & \sigma^{k_1 + v - 1}(\alpha)\\ 
      \sigma^{k_2}(\alpha) & \sigma^{k_2 + 1}(\alpha) & \dots & \sigma^{k_2 + v - 1}(\alpha)\\ 
      \vdots & \vdots & \ddots & \vdots\\ 
      \sigma^{k_v}(\alpha) & \sigma^{k_v + 1}(\alpha) & \dots & \sigma^{k_v + v - 1}(\alpha)\\ 
     \end{pmatrix} = \left(\sigma^{i}(\alpha)s_i\right)_{1 \times v},
  \]
  como queríamos demostrar.
\end{proof}

Como consecuencia de la proposición \ref{prop:pgz-sesgados-magnitudes-error} el proceso de decodificación se reduce a encontrar las coordenadas de error \(\{k_1, \dots, k_v\}\).
Para ello al igual que hicimos en el caso del algoritmo para códigos \textacr{BCH} vamos a definir un polinomio localizador de errores, que en este caso será el que verifique que 
\[
  \lambda = \left[x - \sigma^{k_1}(\beta), x - \sigma^{k_2}(\beta), \dots, x - \sigma^{k_v}(\beta)\right]_{i}.
\]
Por el lema \ref{lem:pol-t-beta} sabemos que este polinomio \(\lambda\) tiene grado \(v\).
Son sus raíces las que nos permitirán determinar las coordenadas de error.
El problema radica por tanto en encontrar este polinomio a partir de la información de la que disponemos.

Observamos que, por definición, un polinomio 
\[
  f = \sum_{k = 0}^{n-1}f_k x^{k} \in \mathcal R\lambda \;\text{ si y solo si }\; x - \sigma^{k_j}(\beta) \mid_d f \quad\text{para todo } j = 1, \dots, v,
\]
o bien, utilizando la norma, si y solo si
\[
  \sum_{k=0}^{n -1}f_k N_k(\sigma^{k_j}(\beta))= 0 \quad\text{para todo } j = 1, \dots, v.
\]
De esta forma podemos expresar la condición \((f_0, \dots, f_{n-1}) \in \mathfrak v(\mathcal R\lambda)\) en forma de ecuación matricial, pues si \((f_0, \dots, f_{n-1}) \in \mathfrak v(\mathcal R\lambda)\) se verifica que \((f_0, \dots, f_n)T = 0\), donde
\[
  T = \begin{pmatrix}
    N_{0}(\sigma^{k_1}(\beta)) & N_{0}(\sigma^{k_2}(\beta)) & \dots & N_{0}(\sigma^{k_v}(\beta))\\
    N_{1}(\sigma^{k_1}(\beta)) & N_{1}(\sigma^{k_2}(\beta)) & \dots & N_{1}(\sigma^{k_v}(\beta))\\
    \vdots & \vdots & & \vdots\\
    N_{n-1}(\sigma^{k_1}(\beta)) & N_{n-1}(\sigma^{k_2}(\beta)) & \dots & N_{n-1}(\sigma^{k_v}(\beta))\\
  \end{pmatrix}.
\]
Esto, junto a que por (\ref{eq:norma-beta}) podemos expresar las normas anteriores como \(N_k(\sigma^{k_j}(\beta)) = \sigma^{k_j}(\alpha)^{-1}\sigma^{k_j + k}(\alpha)\), nos da una forma de obtener todos los elementos de \(\mathcal R\lambda\), pues como deben verificar la ecuación antes comentada, forman el núcleo por la izquierda de la matriz
\[
  \Sigma = \begin{pmatrix}
    \sigma^{k_1}(\alpha) & \sigma^{k_2}(\alpha) & \dots & \sigma^{k_v}(\alpha)\\
    \sigma^{k_1 + 1}(\alpha) & \sigma^{k_2 + 1}(\alpha) & \dots & \sigma^{k_v + 1}(\alpha)\\
    \vdots & \vdots & \ddots & \vdots \\
    \sigma^{k_1 + n - 1}(\alpha) & \sigma^{k_2 + n - 1}(\alpha) & \dots & \sigma^{k_v + n - 1}(\alpha)\\
  \end{pmatrix}
  = \left( \begin{array}{@{}c@{}}
    \Sigma_0\\\hline
    \Sigma_1
  \end{array}\right),
\]
donde \(\Sigma_0\) se corresponde a las primeras \(v + 1\) filas de la matriz \(\Sigma\) anterior.

Consideramos ahora la matriz 
\[
  E = \begin{pmatrix}
    e_1 & \sigma^{-1}(e_1) & \dots & \sigma^{-v + 1}(e_1)\\
    e_2 & \sigma^{-1}(e_2) & \dots & \sigma^{-v + 1}(e_2)\\
    \vdots & \vdots & \ddots & \vdots \\
    e_v & \sigma^{-1}(e_v) & \dots & \sigma^{-v + 1}(e_v)\\
  \end{pmatrix}.
\]
Así podemos considerar la siguiente matriz, que expresaremos por sus entradas para la fila \(k\) y la columna \(i\),
\[
  S = \Sigma E = \left(\sum_{j=1}^v \sigma^{-i}(e_j)\sigma^{k_j+k}(\alpha)\right)_{0 \leq k < n,\; 0 \leq i < v}.
\]
Por (\ref{eq:sindromes-sesgados}), cuando \(k + i < 2t - 1\), la componente \((k, i)\)-ésima puede escribirse como \(\sigma^{-i}(s_{k+i})\sigma^{k}(\alpha)\), de tal forma que podemos dividir la matriz \(S\) como
\[
  S = \left( \begin{array}{@{}c@{}}
    S_0\\\hline
    S_1
  \end{array}\right),
\]
donde \(S_0\) viene dada por
\[
  S_0 = \begin{pmatrix}
    s_0\alpha & \sigma^{-1}(s_1)\alpha & \dots & \sigma^{-v+1}(s_{v-1})\alpha\\
    s_1\sigma(\alpha) & \sigma^{-1}(s_1)\sigma(\alpha) & \dots & \sigma^{-v+1}(s_{v})\sigma(\alpha)\\
    \vdots & \vdots & & \vdots \\
    s_v\sigma^v(\alpha) & \sigma^{-1}(s_{v+1})\sigma^v(\alpha) & \dots & \sigma^{-v+1}(s_{2v-1})\sigma^v(\alpha)\\
  \end{pmatrix}_{(v + 1) \times v}
\]
y cuyos coeficientes pueden calcularse directamente a partir del polinomio \(y\), pues ya no aparecen los \(e_j\).
Para calcular el parámetro \(v\), que es el número de coordenadas de error, utilizaremos un procedimiento análogo al usado en el algoritmo \textacr{PGZ} para códigos \textacr{BCH} cuando buscábamos una matriz de síndromes no singular (de rango máximo).
Para cualquier \(1 \leq r \leq t\) denotaremos por \(S^r\) a la matriz
\[
  S^r = \begin{pmatrix}
    s_0\alpha & \sigma^{-1}(s_1)\alpha & \dots & \sigma^{-r+1}(s_{r-1})\alpha\\
    s_1\sigma(\alpha) & \sigma^{-1}(s_1)\sigma(\alpha) & \dots & \sigma^{-r+1}(s_{r})\sigma(\alpha)\\
    \vdots & \vdots & & \vdots \\
    s_t\sigma^t(\alpha) & \sigma^{-1}(s_{t+1})\sigma^t(\alpha) & \dots & \sigma^{-r+1}(s_{t+r-1})\sigma^t(\alpha)\\
  \end{pmatrix}_{(t + 1) \times r}.
\]
Igual que antes, tenemos que para todo \(r \leq t\) se tiene que \(S^r = \Sigma^tE^r\), donde 
\[
  E^r = \begin{pmatrix}
    e_1 & \sigma^{-1}(e_1) & \dots & \sigma^{-r + 1}(e_1)\\
    e_2 & \sigma^{-1}(e_2) & \dots & \sigma^{-r + 1}(e_2)\\
    \vdots & \vdots & \ddots & \vdots \\
    e_v & \sigma^{-1}(e_v) & \dots & \sigma^{-r + 1}(e_v)\\
  \end{pmatrix}_{v \times r}.
\]
y
\[
  \Sigma^t = \begin{pmatrix}
    \sigma^{k_1}(\alpha) & \sigma^{k_2}(\alpha) & \dots & \sigma^{k_v}(\alpha)\\
    \sigma^{k_1 + 1}(\alpha) & \sigma^{k_2 + 1}(\alpha) & \dots & \sigma^{k_v + 1}(\alpha)\\
    \vdots & \vdots & \ddots & \vdots \\
    \sigma^{k_1 + t}(\alpha) & \sigma^{k_2 + t}(\alpha) & \dots & \sigma^{k_v + t}(\alpha)\\
  \end{pmatrix}_{(t+1)\times v}.
\]

\begin{lemma}
  \label{lem:pgz-sesgados-rangos}
  Para cada \(r \leq t\) se tiene que \(\rank(S^r) = \rank(\Sigma E^r) = \rank(E^r)\).
\end{lemma}

\begin{proof}
  Por \parencite[Lema 2.1]{gomez-torrecillas_petersongorensteinzierler_2018} tiene que \(\rank(\Sigma) = \rank(\Sigma^t) = v\).
  Usando la desigualdad del rango de Sylvester se tiene que
  \[
    \min\{\rank(\Sigma), \rank(E^r)\} \geq \rank(\Sigma E^r) \geq \rank(\Sigma) + \rank E^r - v = \rank(E^r).
  \]
  Por tanto \(\rank(\Sigma E^r) = \rank(E^r)\).
  Con un razonamiento análogo se puede comprobar que \(\rank(S^r) = \rank(E^r)\).
\end{proof}

Hemos de que calcular el mayor valor de \(r\) para el que la matriz \(S^r\) tenga rango máximo.
Por el lema \ref{lem:pgz-sesgados-rangos} que acabamos de demostrar es también el mayor valor de \(r \leq t\) tal que las matrices \(E^r\) y \(\Sigma E^r\) tienen rango máximo.
Denotaremos por \(\mu\) a tal máximo.

\begin{lemma}
  \label{lem:pgz-sesgados-rango-mu}
  Para cada \(r\) tal que \(\mu \leq r \leq t\) se tiene que \(\rank(E^r) = \rank(S^r) = \mu\).
  Por tanto, \(\mu \leq v\).
\end{lemma}

\begin{proof}
  Por el lema \ref{lem:pgz-sesgados-rangos} \(\mu = \rank(E^{\mu}) = \rank(S^{\mu})\), por lo que suponemos que \(\mu < r\).
  Por la maximalidad de \(\mu\) tenemos que la \((\mu + 1)\)-ésima columna de \(E^r\) es una combinación lineal de las \(\mu\) columnas anteriores.
  Aplicando \(\sigma^{-1}\) obtenemos que la \((\mu + 2)\)-ésima columna es una combinación lineal de las columnas segunda a \(\mu + 1\)-ésima, y por tanto una combinación lineal de las primeras \(\mu\) columnas.
  Si repetimos el proceso obtenemos que todas las columnas desde la \((\mu + 1)\)-ésima hasta la \(r\)-ésima son combinaciones lineales de las primeras \(\mu\) columnas, y por tanto \(\rank(E^r) = \mu\).
  Como \(E^r\) tiene \(v\) filas, \(\mu \leq v\).
  Finalmente, \(\rank(S^r) = \mu\) de nuevo por el lema \ref{lem:pgz-sesgados-rangos}.
\end{proof}

\begin{proposition}
  \label{prop:pgz-sesgados-kernel-sesgado}
  El núcleo por la izquierda \(V\) de la matriz \(\Sigma E^{\mu}\) es un código cíclico sesgado.
  Por tanto se tiene que \(\mathfrak v^{-1}(V) = \mathcal R\rho\) para algún polinomio \(\rho \in \mathcal R\) de grado \(\mu\).
  Se tiene además que \(\rho\) es un divisor por la derecha de \(\lambda\).
\end{proposition}

\begin{proof}
  Demostraremos la primera afirmación comprobando que si el vector \((a_0, \dots, a_{n-2}, a_{n-1}) \in V \subseteq \mathbb F_q^n\) también se da que el desplazamiento cíclico del vector anterior \((\sigma(a_{n-1}), \sigma(a_0), \dots, \sigma(a_{n-2})) \in V\).
  Recordemos que el desplazamiento tiene esta forma porque \(xa_ix^{i} = \sigma(a_i)x^{i+1}\) para cada \(0 \leq i \leq n -1\).
  Supongamos entonces que \((a_0, a_1, \dots, a_{n-1})\Sigma E^{\mu} = 0\).
  La maximalidad de \(\mu\) nos asegura que la última columna de \(E^{\mu + 1}\) es una combinación lineal de las \(\mu\) columnas anteriores.
  Por tanto, \((a_0, a_1, \dots, a_{n-1})\Sigma E^{\mu + 1} = 0\).
  Así,
  \begin{align*}
    0 &= (a_0, a_1, \dots, a_{n-1})\Sigma E^{\mu + 1}\\
      &= (a_0, a_1, \dots, a_{n-1})\left( \begin{array}{@{}c|c@{}}
        0 & I_{n-1}\\\hline
        1 & 0
      \end{array}\right)\left( \begin{array}{@{}c|c@{}}
        0 & 1\\\hline
        I_{n-1} & 0
      \end{array}\right)\Sigma E^{\mu + 1}\\
      &= (a_{n-1}, a_0, \dots, a_{n-2})\left( \begin{array}{@{}c|c@{}}
        0 & 1\\\hline
        I_{n-1} & 0
      \end{array}\right)\Sigma E^{\mu + 1}.
  \end{align*}
  Si aplicamos \(\sigma\) a esta ecuación matricial componente a componente obtenemos
  \[
    (\sigma(a_{n-1}), \sigma(a_0), \dots, \sigma(a_{n-2}))\left( \begin{array}{@{}c|c@{}}
      0 & 1\\\hline
      I_{n-1} & 0
    \end{array}\right)\Sigma \sigma(E)\sigma(E^{\mu}) = 0.
  \]
  Observamos que
  \[
    \Sigma = \left( \begin{array}{@{}c|c@{}}
      0 & 1\\\hline
      I_{n-1} & 0
    \end{array}\right)\sigma(\Sigma) \quad\text{y}\quad \sigma(E^{\mu + 1}) = \left( \begin{array}{@{}c|c@{}}
      \sigma(e_1) & \multirow{3}{*}{\(E^{\mu}\)}\\
      \vdots & \\
      \sigma(e_v) & \\
    \end{array}\right)
  \]
  por lo que 
  \[
    (\sigma(a_{n-1}), \sigma(a_0), \dots, \sigma(a_{n-2}))\Sigma \left( \begin{array}{@{}c|c@{}}
      \sigma(e_1) & \multirow{3}{*}{\(E^{\mu}\)}\\
      \vdots & \\
      \sigma(e_v) & \\
    \end{array}\right) = 0.
  \]
  En particular, \((\sigma(a_{n-1}), \sigma(a_0), \dots, \sigma(a_{n-2}))\Sigma E^{\mu} = 0\) por lo que el desplazamiento cíclico \((\sigma(a_{n-1}), \sigma(a_0), \dots, \sigma(a_{n-2})) \in V\), como queríamos.
  Además, dado que cualquier ideal de \(\mathcal R\) es principal, \(\mathfrak v^{-1}(V)\) lo es y estará generado por un polinomio \(\rho \in \mathcal R\).
  Como \(\mathfrak v(\mathcal R \lambda)\) es el núcleo por la izquierda de la matriz \(\Sigma\) por la definición de \(\mathfrak v(\mathcal R \rho)\) como núcleo de \(\Sigma E^{\mu}\) se tiene que \(\mathcal R\lambda \subseteq \mathcal R\rho\), y por tanto \(\rho\) divide por la derecha a \(\lambda\).
  Finalmente la dimensión de \(\mathcal R\rho\) como un \(\mathbb F_q\) espacio vectorial es \(n - \deg(\rho)\).
  Por el lema \ref{lem:pgz-sesgados-rangos} se tiene que \(\rank(\Sigma E^{\mu}) = \mu\) y por tanto \(\deg(\rho) = \mu\).
\end{proof}

El lema siguiente es el que nos va a proporcionar la forma de encontrar el polinomio \(\rho\) que estamos buscando.

\begin{lemma}
  \label{lem:pgz-sesgados-escalonada-st}
  La forma escalonada por columnas de la matriz \(S^t\) es
  \[
    \operatorname{mepc}(S^t) = \left( \begin{array}{@{}c|c@{}}
      I_{\mu} & \multirow{3}{*}{\(0_{(t+ 1)\times (t - \mu)}\)} \\\cline{1-1}
      a_0 \cdots a_{\mu -1 } & \\\cline{1-1}
      H' &
    \end{array}\right),
  \]
  donde \(I_{\mu}\) es la matriz identidad \(\mu \times \mu\) y \(a_0, \dots, a_{\mu - 1} \in \mathbb F_q\) tales que \(\rho = x^{\mu} - \sum_{i = 0}^{\mu - 1}a_ix^{i}\).
\end{lemma}

\begin{proof}
  Por el lema \ref{lem:pgz-sesgados-rango-mu} el \(\rank(S^t) = \mu = \rank(S^{\mu})\), por lo que 
  \[
    \operatorname{mrpc}(S^t) = \left( \begin{array}{@{}c|c@{}}
      \operatorname{mrpc}(S^{\mu}) & 0_{(t + 1) \times (t- \mu)}
    \end{array}\right).
  \]
  La matriz \(S^{\mu}\) consiste en las primeras \(t + 1\) filas de \(\Sigma E^{\mu}\) y ambas tienen el mismo rango \(\mu\), por lo que \(\operatorname{mrpc}(S^{\mu})\) está formada por las primeras \(t + 1\) filas de \(\operatorname{mrpc}(\Sigma E^{\mu})\).
  Por la proposición \ref{prop:pgz-sesgados-kernel-sesgado} \(\mathfrak v(\mathcal R\rho)\) es el núcleo por la izquierda de la matriz \(\operatorname{mrpc}(\Sigma E^{\mu})\).
  Una solución no nula del sistema homogéneo
  \begin{equation}
    \label{eq:pgz-sesgados-mepc-sigma-e-mu}
    X \left( \begin{array}{@{}c|c@{}}
      \multirow{2}{*}{\(\operatorname{mepc}(\Sigma E^{\mu})\)} & 0\\\cline{2-2}
       & I_{n - (\mu + 1)} 
    \end{array}\right) = 0
  \end{equation}
  es un elemento distinto de cero de \(\mathfrak v(\mathcal R(\rho))\) cuyas últimas \(n - (\mu + 1)\) coordenadas son cero.
  Como \(\rho\) tiene grado \(\mu\) y su grado es mínimo en \(\mathcal R \rho\) se deduce que \(\mathfrak v(\rho)\) es la única solución, salvo producto por escalares de (\ref{eq:pgz-sesgados-mepc-sigma-e-mu}).
  Sea \(S_{0}^{\mu}\) la matriz formada por las primeras \(\mu + 1\) filas de \(S^{\mu}\).
  Entonces
  \[
    \operatorname{mepc}(S^{\mu}) = \left( \begin{array}{@{}c@{}}
      \operatorname{mepc}(S_0^{\mu})\\\hline
      H'
    \end{array}\right).
  \]
  Si realizamos más reducciones de columnas utilizando la matriz identidad en el bloque derecho de la matriz (\ref{eq:pgz-sesgados-mepc-sigma-e-mu}) podemos ver que \(\rho\) es también la solución no nula, salvo producto por escalares, del sistema homogéneo
  \begin{equation}
    \label{eq:pgz-sesgados-mepc-sigma-e-mu-4}
    X \left( \begin{array}{@{}c|c@{}}
      \operatorname{mepc}(S_{0}^{\mu}) & 0\\\hline
      0 & I_{n - (\mu + 1)}\\
    \end{array}\right) = 0.
  \end{equation}
  El tamaño de \(\operatorname{mepc}(S_{0}^{\mu})\) es \((\mu + 1) \times \mu\).
  De hecho \(\rank(\operatorname{mepc}(S_{0}^{\mu})) = \mu\) porque el espacio de soluciones de (\ref{eq:pgz-sesgados-mepc-sigma-e-mu-4}) tiene dimensión 1.
  Por tanto solo hay una fila de \(\operatorname{mepc}(S_{0}^{\mu})\) sin pivote.
  Si no es la última entonces habría un polinomio no nulo de \(\mathcal R \rho\) de grado estrictamente menor que \(\mu\), lo cual es imposible.
  Por tanto,
  \[
    \operatorname{mepc}(S_{0}^{\mu}) = \left( \begin{array}{@{}c@{}}
      I_{\mu} \\\hline
      a_0 \dots a_{\mu - 1}
    \end{array}\right).
  \]
  Finalmente \((-a_0, \dots, -a_{\mu - 1}, 1, 0 \dots, 0)\) es una solución no nula de (\ref{eq:pgz-sesgados-mepc-sigma-e-mu-4}), por lo que \(\rho = x^{\mu}- \sigma_{i = 0}^{\mu - 1}a_ix^{i}\).
\end{proof}

 \begin{lemma}
  \label{lem:pgz-sesgados-diagrama}
   Si el ideal por la izquierda \(\mathcal R \rho\) se corresponde, mediante \(\mathfrak v\), con el núcleo por la izquierda de una matriz \(H\) entonces \(H = \Sigma B\) para alguna matriz \(B \in \mathcal M_{v \times \mu}(L)\) que no tiene ninguna fila nula.
 \end{lemma}

\begin{proof}
  Podemos deducir este resultado a partir del siguiente diagrama conmutativo de \(\mathbb F\)-espacios vectoriales.
  \begin{center}
    \begin{tikzcd}[column sep=large, row sep=large]
      0 \arrow[r] & \mathcal R\rho \arrow[r] & \mathcal R \arrow[r, "\cdot H"] & \mathcal R/\mathcal R\rho \arrow[r] & 0\\
      0 \arrow[r] & \mathcal R\lambda \arrow[u, hookrightarrow] \arrow[r] & \mathcal R \arrow[u, equal] \arrow[r, "\cdot \Sigma"] & \mathcal R/\mathcal R\lambda \arrow[u, dashrightarrow, "\cdot B"{right}] \arrow[r] & 0
    \end{tikzcd}
  \end{center}
  Si \(\mathcal R\rho\) se corresponde con el núcleo por la izquierda de una matriz \(H\) entonces existe una aplicación lineal sobreyectiva \(\mathcal R/\mathcal R\lambda \to \mathcal R/\mathcal R\rho\) definida por la multiplicación por la izquierda por una matriz \(B\) de tamaño \(v \times \mu\) tal que \(\Sigma B = H\).
  Como \(\mathcal\rho\) es también	 el núcleo por la izquierda de \(\Sigma E^{\mu}\) existe una matriz no singular \(P\) de tamaño \(\mu \times \mu\) tal que \(\Sigma E^{\mu}P = \Sigma B\).
  Como \(\Sigma\) define una aplicación lineal sobreyectiva, \(E^{\mu}P = B\).
  Finalmente, \(B\) se obtiene a partir de \(E^{\mu}\) realizando operaciones elementales sobre las columnas.
  Como \(E^{\mu}\) no tiene filas nulas, \(B\) tampoco.
\end{proof}

La siguiente proposición nos ilustra sobre la relación existente entre el polinomio \(\rho\) que hemos obtenido y el polinomio localizador de errores \(\lambda\).

\begin{proposition}
  \label{prop:pgz-sesgados-lambda-b-descompone-multiplo-rho}
  Sea \(\lambda' \in \mathcal R\) un polinomio que \(\beta\)-descompone totalmente y es múltiplo de \(\rho\).
  Entonces, \(\lambda \mid_d \lambda'\).
\end{proposition}

\begin{proof}
  Por la proposición \ref{prop:pgz-sesgados-kernel-sesgado} se tiene que \(\rho \mid_d \lambda\) y, por hipótesis, \(\rho \mid_d \lambda'\).
  Así, \(\rho \mid_d (\lambda, \lambda')_{d}\).
  De hecho, por el lema \ref{lem:b-descomposicion-mcm-mcd} el polinomio \((\lambda, \lambda')_{d}\) también \(\beta\)-descompone totalmente.
  Denotemos por \(\phi = (\lambda, \lambda')_{d}\).
  Vamos a demostrar que \(\phi = \lambda\), lo que implica el hecho que queremos demostrar.

  Por definición \(\mathcal R \lambda \subseteq \mathcal R\phi\), por lo que \(\mathcal R\phi\) se corresponde con el núcleo por la izquierda de una matriz \(\Sigma Q\), donde \(Q\) es una matriz de rango máximo.
  De forma análoga se tiene que \(\mathcal R\phi \subseteq \mathcal R\rho\), por lo que existe otra matriz \(Q'\) tal que \(\mathcal R\rho\) es el núcleo por la izquierda de \(\Sigma QQ'\).
  Por el lema \ref{lem:pgz-sesgados-diagrama} se tiene que \(\Sigma QQ' = \Sigma B\), donde \(B\) es una matriz de rango máximo y sin ninguna fila nula.
  Por tanto \(QQ' = B\), porque \(\Sigma\) define una aplicación lineal sobreyectiva y \(Q\) no tiene filas nulas.

  Como \(\phi \mid_d \lambda\) cualquier \(\beta\)-raíz de \(\phi\) tiene que ser también \(\beta\)-raíz de \(\lambda\) por lo que pertenece al conjunto \(\{\sigma^{k_1}(\beta), \dots, \sigma^{k_v}(\beta)\}\).
  Obsérvese que por (\ref{eq:equivalencias-divisor-sigma-b}) se tiene que \(\sigma^{k_j}(\beta)\) es una \(\beta\)-raíz de \(\phi\) si y solo si
  \[
    \rank\left( \begin{array}{@{}c|c@{}}
      \multirow{4}{*}{\(\Sigma Q\)} & \sigma^{k_j}(\alpha)\\
       & \sigma^{k_j + 1}(\alpha)\\
       & \vdots \\
       & \sigma^{k_j + n - 1}(\alpha)
    \end{array}\right) = \rank(\Sigma Q).
  \]
  Por tanto, por el lema \parencite[Lema 2.3]{gomez-torrecillas_petersongorensteinzierler_2018} que \(\phi\) se pueda \(\beta\)-descomponer totalmente implica que \(\{\sigma^{k_1}(\beta), \dots, \sigma^{k_v}(\beta)\}\) es el conjunto de \(\beta\)-raíces de \(\phi\).
  Por tanto, \(\phi = \lambda\).
\end{proof}

Ya estamos en disposición de calcular el polinomio localizador de errores y por tanto hemos completado el diseño del algoritmo de Peterson-Gorenstein-Zierler para códigos cíclicos sesgados, que puede consultarse en el algoritmo \ref{alg:pgz-sesgados}.

\begin{Ualgorithm}[htbp]
  \small
  \DontPrintSemicolon
  \KwIn{el código \(\mathcal C\), el mensaje recibido \(y = (y_0, \dots, y_{n-1}) \in \mathbb F_q^n\) con no más de \(t\) errores}
  \KwOut{el error \(e = (e_0, \dots, e_{n-1})\) tal que \(y - e \in \mathcal C\)}
  \tcp{Paso 1: calcular síndromes}
  \For{\(0 \leq i \leq 2t - 1\)}{
      $s_i \longleftarrow \sum_{j=0}^{n-1}y_jN_j(\sigma^i(\beta))$\;
  }
  \If{\(s_i = 0\) para todo \(0 \leq i \leq 2t - 1\)}{\Return{\(0\)}}
  \tcp{Paso 2: hallar polinomio localizador y las coordenadas de error}
  \(S^t \longleftarrow \left(\sigma^{-j}(s_{i+j})\sigma^i(\alpha)\right)_{0 \leq i \leq t, 0 \leq j \leq t -1}\)\;
  Calcular
  \[
    \operatorname{mepc}(S^t) = \left( \begin{array}{@{}c|c@{}}
      I_{\mu} & \multirow{3}{*}{\(0_{(t+ 1)\times (t - \mu)}\)} \\\cline{1-1}
      a_0 \cdots a_{\mu -1 } & \\\cline{1-1}
      H' &
    \end{array}\right)
  \]\label{algl:pgz-sesgados-mpec-St}\vspace*{-1.5em}\;% Reducimos un poco el espacio vertical
  \(\rho = (\rho_0, \dots, \rho_{\mu}) \longleftarrow (-a_0, \dots, -a_{\mu-1}, 1)\) y \(\rho N \longleftarrow (\rho_0, \dots, \rho_{\mu}, 0, \dots, 0)N\)\;\label{algl:pgz-sesgados-rho}
  \(\{k_1, \dots, k_v\} \longleftarrow \) coordenadas igual a cero de \(\rho N\)\;\label{algl:pgz-sesgados-pos-error}
  \If{\(\mu \neq v\)}{\label{algl:pgz-sesgados-if}
    Calcular \[M_{\rho} \longleftarrow \begin{pmatrix}
      \rho_0 & \rho_1 & \dots & \rho_{\mu} & 0 & \dots & 0\\
      0 & \sigma(\rho_0) & \dots & \sigma(\rho_{\mu - 1}) & \sigma(\rho_{\mu}) & \dots & 0\\
       & & \ddots & & & \ddots & \\
      0 & \dots & 0 & \sigma^{n - \mu - 1}(\rho_0) & \dots & \dots & \sigma^{n - \mu - 1}(\rho_{\mu})
    \end{pmatrix}_{(n - \mu) \times n}\]\vspace*{-1.5em}\;% Reducimos un poco el espacio vertical
    \(N_{\rho} \longleftarrow M_{\rho}N\)\;
    \(H_{\rho} \longleftarrow \operatorname{mepf}(N_{\rho})\)\;\label{algl:pgz-sesgados-mpec-Nrho}
    \(H' \longleftarrow\) la matriz obtenida al eliminar las filas de \(H_{\rho}\) distintas de \(\varepsilon_i\) para algún \(i\)\;\label{algl:pgz-sesgados-h-prima}
    \(\{k_1, \dots, k_v\} \longleftarrow\) las coordenadas de las columnas igual a cero de \(H'\)\;
  }
  \tcp{Paso 3: resolver el sistema de los síndromes, obteniendo las magnitudes de error}
  Encontrar \((x_1, \dots, x_v)\) tal que \((x_1, \dots, x_v)(\Sigma^{v-1})^T = (\alpha s_0, \sigma(\alpha)s_1, \dots, \sigma^{v-1}(\alpha)s_{v-1})\)\;\label{algl:pgz-sesgados-solucion-sistema}
  \tcp{Paso 4: construir el error y devolverlo}
  \Return{\((e_0, \dots, e_{n-1})\) con \(e_i = x_i\) para \(i \in \{k_1, \dots, k_v\}\), cero en otro caso}\label{algl:pgz-sesgados-error}
  \caption{Peterson-Gorenstein-Zierler para códigos cíclicos sesgados.}
  \label{alg:pgz-sesgados}
\end{Ualgorithm}

\begin{theorem}
  Sea \(\mathbb F_q\) un cuerpo finito, \(\sigma \in \operatorname{Aut}(\mathbb F_q)\) de orden \(n\) y \(\mathbb F_q^{\sigma}\) el subcuerpo invariante del generado por \(\sigma\).
  Sea \(\{\alpha, \sigma(\alpha), \dots, \sigma^{n-1}(\alpha)\}\) una base normal de \(\mathbb F_q\) sobre \(\mathbb F_{q}\) y \(\beta = \alpha^{-1}\sigma(\alpha)\).
  Sean \(\mathcal R = \mathbb F_q[x; \sigma]/(x^n - 1)\), \(g = \left[x - \beta, \dots, x - \sigma^{\delta - 2}(\beta)\right]_{i}\) y \(\mathcal C\) el código \textacr{RS} sesgado tal que \(\mathfrak v^{-1}(\mathcal C) = \mathcal Rg\).
  Entonces el algoritmo descrito en el algoritmo \ref{alg:pgz-sesgados} encuentra correctamente el error \(e = (e_0, \dots, e_{n-1})\) de cualquier vector recibido si el número de coordenadas distintas de cero de \(e\) es \(v \leq t = \lfloor (\delta - 1)/2 \rfloor\).
\end{theorem}

\begin{proof}
  Tras los ajustes iniciales la línea \ref{algl:pgz-sesgados-rho} calcula un polinomio \(\rho = \sum_{i = 0}^{\mu}\rho_ix^{i}\) como describe el lema \ref{lem:pgz-sesgados-escalonada-st} y que, por la proposición \ref{prop:pgz-sesgados-kernel-sesgado}, es divisor por la izquierda del polinomio localizador de errores \(\lambda\).
  
  Por (\ref{eq:equivalencias-divisor-sigma-b}) la línea \ref{algl:pgz-sesgados-pos-error} calcula todas las \(\beta\)-raíces de \(\rho\).
  Sabemos por el lema \ref{lem:pol-t-beta} que el número de \(\beta\)-raíces es \(v = \mu\) si y solo si \(\rho\) —de grado \(\mu\)— puede \(\beta\)-descomponerse totalmente.
  En ese caso, por la proposición \ref{prop:pgz-sesgados-lambda-b-descompone-multiplo-rho} \(\rho = \lambda\).
  
  Si por el contrario \(v \neq \mu\) como el \(\deg(\rho) = \mu\) las filas de \(M_{\rho}\) generan \(\mathcal R\rho\) como un \(\mathbb F_q\) espacio vectorial y las fila de \(N_{\rho}\) también generan \(\mathcal R\rho\) bajo el cambio de base correspondiente a \(N\).
  Como \(H_{\rho}\) es la forma reducida por columnas de \(M_{\rho}\) entonces sus filas también son una base de \(\mathcal \rho\) como un \(\mathbb F_q\)- espacio vectorial.
  Por el lema \ref{lem:matriz-mf-base} las filas de \(H'\) generan un \(\mathbb F_q\)-subespacio vectorial \(\mathcal R\lambda'\) para algún polinomio \(\lambda'\) que puede \(\beta\)-descomponerse totalmente.
  Como \(H'\) se obtiene eliminando algunas filas de \(H_{\rho}\) el polinomio \(\lambda'\) tiene que tener mayor grado que \(\rho\) y se deduce que \(\rho \mid_d \lambda'\).

  Vamos a ver que el polinomio que hemos encontrado es el polinomio localizador de errores, \(\lambda' = \lambda\).
  Como \(\rho \mid_d \lambda'\) por la proposición \ref{prop:pgz-sesgados-lambda-b-descompone-multiplo-rho} se tiene que \(\lambda \mid_d \lambda'\).
  Procederemos por reducción al absurdo.
  Supongamos entonces que \(\lambda \neq \lambda'\).
  Entonces la matriz \(H_{\lambda} = \operatorname{mepf}(M_{\lambda}N)\) contiene al menos una fila adicional, que será un vector canónico \(\varepsilon_{d}\), que no está en \(H'\).
  Como \(\rho \mid_d \lambda\) por definición se tiene que \(\mathcal R\lambda \subseteq \mathcal R\rho\) y por tanto,
  \[
    \rank\left( \begin{array}{@{}c@{}}
      H_{\rho}\\\hline
      \varepsilon_{d}
    \end{array}\right) = \rank (H_{\rho}).
  \]
  Por \parencite[Lema 2.4]{gomez-torrecillas_petersongorensteinzierler_2018} \(\varepsilon_{d}\) es una fila de \(H_{\rho}\), por lo que la línea \ref{algl:pgz-sesgados-h-prima} no la elimina, y en consecuencia, \(\varepsilon_{d}\) pertenece a \(H'\), lo que se contradice con la afirmación anterior.
  Concluimos entonces que \(\lambda = \lambda'\).
  Una vez obtenido el polinomio localizador de errores \(\lambda\) podemos calcular las coordenadas de error a partir de sus \(\beta\)-raíces.
  Finalmente, por la proposición \ref{prop:pgz-sesgados-magnitudes-error}, la línea \ref{algl:pgz-sesgados-solucion-sistema} calcula las magnitudes de error.
  Con ellas ya podemos construir el polinomio de error en la línea \ref{algl:pgz-sesgados-error} y obtener el mensaje.
\end{proof}

En cuanto a lo que a la eficiencia del algoritmo respecta, la complejidad del mismo está dominada por el cálculo de las formas reducidas por filas de las líneas \ref{algl:pgz-sesgados-mpec-St} y \ref{algl:pgz-sesgados-mpec-Nrho}.
Dichas operaciones tienen un orden de complejidad de \(\mathcal{O}(t^3)\) y \(\mathcal{O}(n^3)\), respectivamente.
Como en el peor de los casos \(t \approx n/2\), el orden de complejidad de este algoritmo es \(\mathcal{O}(n^3)\).
Sin embargo, la mayoría de veces la condición de la línea \ref{algl:pgz-sesgados-if} no se verifica, y por tanto solo se realiza uno de los dos cálculos de matrices escalonadas \parencite[ver][Remark 1]{gomez-torrecillas_petersongorensteinzierler_2018}.

Veamos a continuación algunos ejemplos utilizando para ello la implementación en SageMath comentada en el anexo \ref{annex:pgz-sage}.

\begin{example}
  Sea \(\mathbb F = \mathbb F_2(a)\) un cuerpo con \(2^{12} = 1024\) elementos, donde se verifica la relación \(a^{12} + a^7 + a^{6} + a^{5} + a^{3} + a + 1 = 0\).
  Consideremos el automorfismo \(\sigma: \mathbb F \to \mathbb F\) dado por \(\sigma = \sigma_2^{10}\), donde \(\sigma_2\) es el automorfismo de Frobenius, de tal forma que \(\sigma(a) = a^{1024}\).
  El orden de \(\sigma\) es \(6\) por lo que un código cíclico sobre \(\mathbb F\) es un ideal por la izquierda del cociente \(\mathcal R = \mathbb F[x; \sigma]/(x^{6} - 1)\).
  Tomaremos \(\alpha = a\), lo que nos proporciona una base normal de \(\mathbb F\), y \(\beta = \sigma(a)a^{-1} = a^{1023}\).
  Las imágenes de \(\beta\) por las potencias de \(\sigma\) nos da el conjunto \(\{a^{1023}, a^{3327}, a^{3903}, a^{4047}, a^{4083}, a^{4092}\}\).
  Consideremos el código \textacr{RS} sesgado generado por
  \begin{align*}
    g &= \left[x - a^{1023}, x - a^{3327}, x - a^{3903}, x - a^{4047}\right]_i \\
      &= x^4 + a^{2103}x^3 + a^{687}x^2 + a^{1848} + a^{759}.
  \end{align*}
  Vamos a seguir este ejemplo utilizando SageMath.
  \begin{lstlisting}[gobble=4]
    sage: F.<a> = GF(2^12)
    sage: a^12
    > a^7 + a^6 + a^5 + a^3 + a + 1
    sage: Frob = F.frobenius_endomorphism()
    sage: sigma = Frob^10
    sage: S.<x> = SkewPolynomialRing(F, sigma); S
    > Skew Polynomial Ring in x over Finite Field in a of size 2^12 twisted by a |--> a^(2^10)
    sage: b = a^-1*sigma(a)
    sage: g = left_lcm([x - a^1023, x - a^3327, x - a^3903, x - a^4047])
    sage: C = SkewRSCode(generator_pol=g); C
    > [6, 2] Skew RS Code on Skew Polynomial Ring in x over Finite Field in a of size 2^12 twisted by a |--> a^(2^10)
  \end{lstlisting}
  Definimos el decodificador basado en el algoritmo \textacr{PGZ}.
  \begin{lstlisting}[gobble=4]
    sage: D = SkewRSPGZDecoder(C); D
    > Peterson-Gorenstein-Zierler algorithm based decoder for [6, 2] Skew RS Code on Skew Polynomial Ring in x over Finite Field in a of size 2^12 twisted by a |--> a^(2^10)
    sage: D.correction_capability()
    > 2
  \end{lstlisting}
  Supongamos que queremos enviar el mensaje \(m = x + a\), por lo que el polinomio codificado se obtiene como \(c = mg\).
  \begin{lstlisting}[gobble=4]
    sage: c = C.encode(x + a, "SkewCyclicPolynomialEncoder"); c
    > (a^9 + a^8 + a^6 + a^5 + a^2 + a + 1, a^9 + a^6 + a^5 + a^4 + a^3 + 1, a^11 + a^9 + a^8 + a^2 + a + 1, a^11 + a^10 + a^8 + a^6 + a^4 + a^3 + a^2 + 1, a^11 + a^8 + a^7 + a^6 + a^5 + a^4 + a^3 + a^2 + a, 1)
  \end{lstlisting}
  Este vector equivale a la expresión polinómica \(c = x^5 + a^{3953}x^4 + a^{1333}x^3 + a^{2604}x^2 + a^{1596}x + a^{760}\).
  Supongamos que se ha recibido tras la transmisión el vector \(y = x^5 + a^{3953}x^4 + a^{671}x^3 + a^{2604}x^2 + a^{1596}x + a^{3699}\).
  \begin{lstlisting}[gobble=4]
    sage: y = x^5 + a^3953*x^4 + a^671*x^3 + a^2604*x^2 + a^1596*x + a^3699; y
    > x^5 + (a^11 + a^8 + a^7 + a^6 + a^5 + a^4 + a^3 + a^2 + a)*x^4 + (a^11 + a^10 + a^8 + a^6 + a^4 + a^2 + 1)*x^3 + (a^11 + a^9 + a^8 + a^2 + a + 1)*x^2 + (a^9 + a^6 + a^5 + a^4 + a^3 + 1)*x + a^9 + a^8 + a^6 + a^5 + a + 1
  \end{lstlisting}
  Vamos a utilizar el decodificador definido antes.
  \begin{lstlisting}[gobble=4, basicstyle=\small\ttfamily]
    sage: D.decode_to_code(y)
    > Peterson-Gorenstein-Zierler algorithm based decoder for [6, 2] Skew RS Code on Skew Polynomial Ring in x over Finite Field in a of size 2^12 twisted by a |--> a^(2^10)
    sage: D.correction_capability()
    > 2
    sage: D.decode_to_code(y)
    DEBUG: s, syndromes vector: [a^10 + a^6 + a^5 + a^3, a^11 + a^10 + a^7 + a^5 + a^4 + a^3 + a^2 + a, a^11 + a^9 + a^8 + a^5 + a^4 + a^2 + a, a^11 + a^10 + a^6 + a^3 + a^2 + a + 1]
      S_t:
      [                    a^11 + a^7 + a^6 + a^4 a^10 + a^7 + a^6 + a^5 + a^4 + a^2 + a + 1]
      [            a^11 + a^9 + a^4 + a^2 + a + 1            a^9 + a^8 + a^7 + a^5 + a^2 + a]
      [             a^9 + a^6 + a^4 + a^3 + a + 1          a^11 + a^10 + a^9 + a^4 + a^2 + 1]
      rcef_S_t:
      [                                              1                                               0]
      [                                              0                                               1]
      [a^11 + a^10 + a^9 + a^8 + a^7 + a^6 + a^5 + a^4                      a^10 + a^8 + a^7 + a^2 + 1]
      rho: [a^11 + a^10 + a^9 + a^8 + a^7 + a^6 + a^5 + a^4, a^10 + a^8 + a^7 + a^2 + 1, 1]
      rho_N: (0, a^11 + a^8 + a^7 + a^6 + a^4 + a^3 + a^2 + a, a^10 + a^9 + a^8 + a^7 + a^5 + a^3 + a^2 + 1, 0, a^9 + a^8 + a^6 + a^3 + a^2 + a + 1, a^10 + a^8 + a^7 + a^4 + a^3 + a + 1)
      k: [0, 3]
      v: 2
      Note: solve for E, where E*Sigma.transpose() = b_syn
      Sigma:
      [                                  a             a^8 + a^4 + a^3 + a + 1]
      [ a^11 + a^9 + a^8 + a^5 + a^4 + a^2 a^11 + a^10 + a^9 + a^7 + a^5 + a^4]
      b_syn: [a^11 + a^7 + a^6 + a^4, a^11 + a^9 + a^4 + a^2 + a + 1]
      E: (a^2, a^3)
      error: a^3*x^3 + a^2
      m = y - e: x^5 + (a^11 + a^8 + a^7 + a^6 + a^5 + a^4 + a^3 + a^2 + a)*x^4 + (a^11 + a^10 + a^8 + a^6 + a^4 + a^3 + a^2 + 1)*x^3 + (a^11 + a^9 + a^8 + a^2 + a + 1)*x^2 + (a^9 + a^6 + a^5 + a^4 + a^3 + 1)*x + a^9 + a^8 + a^6 + a^5 + a^2 + a + 1
    > (a^9 + a^8 + a^6 + a^5 + a^2 + a + 1, a^9 + a^6 + a^5 + a^4 + a^3 + 1, a^11 + a^9 + a^8 + a^2 + a + 1, a^11 + a^10 + a^8 + a^6 + a^4 + a^3 + a^2 + 1, a^11 + a^8 + a^7 + a^6 + a^5 + a^4 + a^3 + a^2 + a, 1)
  \end{lstlisting}
  Y efectivamente podemos comparar ambos valores para comprobar que son el mismo.
  \begin{lstlisting}[gobble=4]
    sage: C.encode(x + a, "SkewCyclicPolynomialEncoder") == D.decode_to_code(y)
    > True
  \end{lstlisting}

  Supongamos ahora que al mensaje \(x + a\) codificado se le suma un error \(e = a^2 + a^{1367}*x^3\), de forma que \(y = c + e\).

  \begin{lstlisting}[gobble=4]
    sage: y_ = S(c.list()) + a^2 + a^1367*x^3; y_
    > x^5 + (a^11 + a^8 + a^7 + a^6 + a^5 + a^4 + a^3 + a^2 + a)*x^4 + (a^11 + a^7 + a^6 + a^5 + a^3 + a^2)*x^3 + (a^11 + a^9 + a^8 + a^2 + a + 1)*x^2 + (a^9 + a^6 + a^5 + a^4 + a^3 + 1)*x + a^9 + a^8 + a^6 + a^5 + a + 1
  \end{lstlisting}

  Al decodificar este mensaje nos encontraremos en el caso en el que \(\mu \neq v\).

  \begin{lstlisting}[gobble=4, basicstyle=\small\ttfamily]
    sage: D.decode_to_code(y_)
    > (...)
      rho: [a^10 + a^8 + a^7 + a^5 + a^3 + a^2, 1]
      rho_N: (a^5 + a^4 + a^2 + a, a^10 + a^9 + a^6 + a^5 + a^3 + a^2 + 1, a^7 + a^4 + a, a^9, a^11 + a^10 + a^9 + a^8 + a^5 + a^4 + a^2 + a, a^11 + a^9 + a^8 + a^7 + a^6 + a^5 + a^4 + a^3 + a^2 + a)
      Case mu != v
      (...)
      error: (a^10 + a^8 + a^7 + a^5 + a^4 + 1)*x^3 + a^2
    > (a^9 + a^8 + a^6 + a^5 + a^2 + a + 1, a^9 + a^6 + a^5 + a^4 + a^3 + 1, a^11 + a^9 + a^8 + a^2 + a + 1, a^11 + a^10 + a^8 + a^6 + a^4 + a^3 + a^2 + 1, a^11 + a^8 + a^7 + a^6 + a^5 + a^4 + a^3 + a^2 + a, 1)
  \end{lstlisting}

  De nuevo, podemos comprobar que efectivamente el mensaje decodificado es igual al mensaje original.

  \begin{lstlisting}[gobble=4]
    sage: C.encode(a + x, "SkewCyclicPolynomialEncoder") == D.decode_to_code(y_)
    > True
  \end{lstlisting}

\end{example}